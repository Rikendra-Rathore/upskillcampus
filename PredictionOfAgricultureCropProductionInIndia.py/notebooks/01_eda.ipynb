{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f3e6fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c3a79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD set to: C:\\Users\\riken\\Downloads\\Agriculture_Production\n"
     ]
    }
   ],
   "source": [
    "# Cell-1: Set working directory to project root (auto)\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Try to move up until we find the folder that has 'data' and 'src'\n",
    "p = Path.cwd()\n",
    "for _ in range(5):  # max 5 levels up\n",
    "    if (p / \"data\").exists() and (p / \"src\").exists():\n",
    "        os.chdir(p)\n",
    "        break\n",
    "    p = p.parent\n",
    "\n",
    "print(\"CWD set to:\", Path.cwd())  # should be .../Agriculture_Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03f32364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (275, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crop</th>\n",
       "      <th>variety</th>\n",
       "      <th>state</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>quantity</th>\n",
       "      <th>production</th>\n",
       "      <th>unit</th>\n",
       "      <th>cost</th>\n",
       "      <th>recommended_zone</th>\n",
       "      <th>source_file</th>\n",
       "      <th>source_sheet</th>\n",
       "      <th>area_ha</th>\n",
       "      <th>yield_q_ha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total Foodgrains</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "      <td>128.5</td>\n",
       "      <td>158.8</td>\n",
       "      <td>Tons</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>datafile2.csv</td>\n",
       "      <td>csv</td>\n",
       "      <td>128.5</td>\n",
       "      <td>123.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "      <td>168.5</td>\n",
       "      <td>200.8</td>\n",
       "      <td>Tons</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>datafile2.csv</td>\n",
       "      <td>csv</td>\n",
       "      <td>168.5</td>\n",
       "      <td>119.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "      <td>115.0</td>\n",
       "      <td>131.6</td>\n",
       "      <td>Tons</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>datafile2.csv</td>\n",
       "      <td>csv</td>\n",
       "      <td>115.0</td>\n",
       "      <td>114.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jowar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "      <td>120.7</td>\n",
       "      <td>124.3</td>\n",
       "      <td>Tons</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>datafile2.csv</td>\n",
       "      <td>csv</td>\n",
       "      <td>120.7</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bajra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "      <td>94.5</td>\n",
       "      <td>136.4</td>\n",
       "      <td>Tons</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>datafile2.csv</td>\n",
       "      <td>csv</td>\n",
       "      <td>94.5</td>\n",
       "      <td>144.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               crop  variety  state  season  year  quantity  production  unit  \\\n",
       "0  Total Foodgrains      NaN    NaN     NaN  2007     128.5       158.8  Tons   \n",
       "1              Rice      NaN    NaN     NaN  2007     168.5       200.8  Tons   \n",
       "2             Wheat      NaN    NaN     NaN  2007     115.0       131.6  Tons   \n",
       "3             Jowar      NaN    NaN     NaN  2007     120.7       124.3  Tons   \n",
       "4             Bajra      NaN    NaN     NaN  2007      94.5       136.4  Tons   \n",
       "\n",
       "   cost  recommended_zone    source_file source_sheet  area_ha  yield_q_ha  \n",
       "0   NaN               NaN  datafile2.csv          csv    128.5       123.6  \n",
       "1   NaN               NaN  datafile2.csv          csv    168.5       119.2  \n",
       "2   NaN               NaN  datafile2.csv          csv    115.0       114.4  \n",
       "3   NaN               NaN  datafile2.csv          csv    120.7       103.0  \n",
       "4   NaN               NaN  datafile2.csv          csv     94.5       144.3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell-2: Load the combined CSV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"data/interim/agri_combined.csv\")\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cb814b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (275, 14)\n",
      "After cleaning: (275, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crop</th>\n",
       "      <th>variety</th>\n",
       "      <th>state</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>quantity</th>\n",
       "      <th>production</th>\n",
       "      <th>unit</th>\n",
       "      <th>cost</th>\n",
       "      <th>recommended_zone</th>\n",
       "      <th>source_file</th>\n",
       "      <th>source_sheet</th>\n",
       "      <th>area_ha</th>\n",
       "      <th>yield_q_ha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total Foodgrains</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "      <td>128.5</td>\n",
       "      <td>158.8</td>\n",
       "      <td>Tons</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>datafile2.csv</td>\n",
       "      <td>csv</td>\n",
       "      <td>128.5</td>\n",
       "      <td>123.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "      <td>168.5</td>\n",
       "      <td>200.8</td>\n",
       "      <td>Tons</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>datafile2.csv</td>\n",
       "      <td>csv</td>\n",
       "      <td>168.5</td>\n",
       "      <td>119.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "      <td>115.0</td>\n",
       "      <td>131.6</td>\n",
       "      <td>Tons</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>datafile2.csv</td>\n",
       "      <td>csv</td>\n",
       "      <td>115.0</td>\n",
       "      <td>114.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jowar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "      <td>120.7</td>\n",
       "      <td>124.3</td>\n",
       "      <td>Tons</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>datafile2.csv</td>\n",
       "      <td>csv</td>\n",
       "      <td>120.7</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bajra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "      <td>94.5</td>\n",
       "      <td>136.4</td>\n",
       "      <td>Tons</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>datafile2.csv</td>\n",
       "      <td>csv</td>\n",
       "      <td>94.5</td>\n",
       "      <td>144.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               crop variety state season  year  quantity  production  unit  \\\n",
       "0  Total Foodgrains     NaN   NaN    NaN  2007     128.5       158.8  Tons   \n",
       "1              Rice     NaN   NaN    NaN  2007     168.5       200.8  Tons   \n",
       "2             Wheat     NaN   NaN    NaN  2007     115.0       131.6  Tons   \n",
       "3             Jowar     NaN   NaN    NaN  2007     120.7       124.3  Tons   \n",
       "4             Bajra     NaN   NaN    NaN  2007      94.5       136.4  Tons   \n",
       "\n",
       "   cost recommended_zone    source_file source_sheet  area_ha  yield_q_ha  \n",
       "0   NaN              NaN  datafile2.csv          csv    128.5       123.6  \n",
       "1   NaN              NaN  datafile2.csv          csv    168.5       119.2  \n",
       "2   NaN              NaN  datafile2.csv          csv    115.0       114.4  \n",
       "3   NaN              NaN  datafile2.csv          csv    120.7       103.0  \n",
       "4   NaN              NaN  datafile2.csv          csv     94.5       144.3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['crop', 'variety', 'state', 'season', 'year', 'quantity', 'production', 'unit', 'cost', 'recommended_zone', 'source_file', 'source_sheet', 'area_ha', 'yield_q_ha']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# df already loaded in your notebook. If not:\n",
    "# df = pd.read_csv(\"data/interim/agri_combined.csv\")\n",
    "\n",
    "print(\"Original shape:\", df.shape)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Ensure numeric types\n",
    "for col in ['production','quantity','cost','year']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Keep only rows with valid non-negative production\n",
    "df = df[df['production'].notna() & (df['production'] >= 0)]\n",
    "\n",
    "# Clean basic text columns\n",
    "for col in ['crop','variety','state','season','unit','recommended_zone']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "        df.loc[df[col].isin(['nan','None','NaN']), col] = np.nan\n",
    "\n",
    "print(\"After cleaning:\", df.shape)\n",
    "display(df.head())\n",
    "print(\"Columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cf44205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Years: [2007, 2008, 2009, 2010, 2011]\n",
      "\n",
      "Missing ratio per column:\n",
      " variety             1.0\n",
      "state               1.0\n",
      "season              1.0\n",
      "cost                1.0\n",
      "recommended_zone    1.0\n",
      "crop                0.0\n",
      "year                0.0\n",
      "quantity            0.0\n",
      "production          0.0\n",
      "unit                0.0\n",
      "source_file         0.0\n",
      "source_sheet        0.0\n",
      "area_ha             0.0\n",
      "yield_q_ha          0.0\n",
      "dtype: float64\n",
      "\n",
      "States: 0\n",
      "Crops: 55\n",
      "\n",
      "Production summary:\n",
      " count     275.000000\n",
      "mean      183.042182\n",
      "std       196.681803\n",
      "min        42.100000\n",
      "25%       116.650000\n",
      "50%       155.400000\n",
      "75%       199.050000\n",
      "max      1790.600000\n",
      "Name: production, dtype: float64\n",
      "\n",
      "Top 10 stateâ€“crop by total production:\n",
      " Series([], Name: production, dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Years:\", sorted(df['year'].dropna().unique().tolist()) if 'year' in df.columns else \"No year\")\n",
    "print(\"\\nMissing ratio per column:\\n\", df.isna().mean().sort_values(ascending=False))\n",
    "\n",
    "if 'state' in df.columns:\n",
    "    print(\"\\nStates:\", df['state'].nunique())\n",
    "if 'crop' in df.columns:\n",
    "    print(\"Crops:\", df['crop'].nunique())\n",
    "\n",
    "print(\"\\nProduction summary:\\n\", df['production'].describe())\n",
    "\n",
    "if set(['state','crop']).issubset(df.columns):\n",
    "    top = df.groupby(['state','crop'])['production'].sum().sort_values(ascending=False).head(10)\n",
    "    print(\"\\nTop 10 stateâ€“crop by total production:\\n\", top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0354f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features: ['crop', 'year', 'quantity', 'area_ha', 'yield_q_ha']\n",
      "Unique years: [2007, 2008, 2009, 2010, 2011]\n",
      "Split sizes -> train: (110, 14) valid: (55, 14) test: (110, 14)\n"
     ]
    }
   ],
   "source": [
    "target = 'production'\n",
    "\n",
    "# Auto-select features (drop target + helper cols)\n",
    "drop_cols = {target, 'source_file', 'source_sheet'}\n",
    "feature_cols = [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "# Drop all-null or constant columns\n",
    "feature_cols = [c for c in feature_cols if df[c].notna().any()]\n",
    "feature_cols = [c for c in feature_cols if df[c].nunique(dropna=True) > 1]\n",
    "print(\"Using features:\", feature_cols)\n",
    "\n",
    "# Time-aware split\n",
    "years = sorted(df['year'].dropna().unique().tolist()) if 'year' in df.columns else []\n",
    "print(\"Unique years:\", years)\n",
    "\n",
    "if len(years) >= 4:\n",
    "    test_years  = years[-2:]\n",
    "    valid_years = [years[-3]]\n",
    "    train_years = [y for y in years if y not in test_years + valid_years]\n",
    "elif len(years) == 3:\n",
    "    test_years  = [years[-1]]\n",
    "    valid_years = [years[-2]]\n",
    "    train_years = [years[0]]\n",
    "elif len(years) == 2:\n",
    "    test_years  = [years[-1]]\n",
    "    valid_years = []\n",
    "    train_years = [years[0]]\n",
    "else:\n",
    "    # Fallback: random split if years not available/too few\n",
    "    test_years, valid_years, train_years = [], [], []\n",
    "\n",
    "if train_years:\n",
    "    train = df[df['year'].isin(train_years)]\n",
    "    remain = df[~df.index.isin(train.index)]\n",
    "    valid = remain[remain['year'].isin(valid_years)] if valid_years else remain.sample(frac=0.5, random_state=42)\n",
    "    test  = remain[~remain.index.isin(valid.index)] if test_years else df.sample(frac=0.2, random_state=42)\n",
    "else:\n",
    "    # random split fallback\n",
    "    train = df.sample(frac=0.7, random_state=42)\n",
    "    remain = df.drop(train.index)\n",
    "    valid = remain.sample(frac=0.5, random_state=42)\n",
    "    test  = remain.drop(valid.index)\n",
    "\n",
    "print(\"Split sizes -> train:\", train.shape, \"valid:\", valid.shape, \"test:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80c67ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (valid) by ['state', 'crop', 'season'] | MAE: 71.93 | RMSE: 35420.17 | R2: -0.027\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate(y_true, y_pred, name=\"\"):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred,)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"{name} | MAE: {mae:.2f} | RMSE: {rmse:.2f} | R2: {r2:.3f}\")\n",
    "\n",
    "# choose grouping columns present\n",
    "group_cols = [c for c in ['state','crop','season'] if c in df.columns]\n",
    "if not group_cols:\n",
    "    group_cols = [c for c in ['state','crop'] if c in df.columns]\n",
    "\n",
    "def group_median_baseline(train_df, apply_df, group_cols, target='production'):\n",
    "    med = train_df.groupby(group_cols)[target].median()\n",
    "    default = train_df[target].median()\n",
    "    preds = []\n",
    "    for _, row in apply_df[group_cols].iterrows():\n",
    "        key = tuple(row.values)\n",
    "        preds.append(med.get(key, default))\n",
    "    return np.array(preds)\n",
    "\n",
    "if group_cols:\n",
    "    base_valid = group_median_baseline(train, valid, group_cols, target)\n",
    "    evaluate(valid[target], base_valid, f\"Baseline (valid) by {group_cols}\")\n",
    "else:\n",
    "    print(\"Skipping baseline: no suitable grouping columns found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6267796b-4368-4238-a057-4a7df2267834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 185.7837188\ttest: 183.1805506\tbest: 183.1805506 (0)\ttotal: 189ms\tremaining: 4m 42s\n",
      "200:\tlearn: 10.6006114\ttest: 18.5537818\tbest: 18.5537818 (200)\ttotal: 14.4s\tremaining: 1m 33s\n",
      "400:\tlearn: 2.0545811\ttest: 16.4330781\tbest: 16.4330781 (400)\ttotal: 32.6s\tremaining: 1m 29s\n",
      "600:\tlearn: 0.7964589\ttest: 16.2174901\tbest: 16.2174901 (600)\ttotal: 48.8s\tremaining: 1m 12s\n",
      "800:\tlearn: 0.4463215\ttest: 16.2357827\tbest: 16.2115652 (622)\ttotal: 1m 6s\tremaining: 58.1s\n",
      "1000:\tlearn: 0.2899293\ttest: 16.2328388\tbest: 16.2115652 (622)\ttotal: 1m 23s\tremaining: 41.6s\n",
      "1200:\tlearn: 0.2009692\ttest: 16.2408032\tbest: 16.2115652 (622)\ttotal: 1m 39s\tremaining: 24.8s\n",
      "1400:\tlearn: 0.1450130\ttest: 16.2483412\tbest: 16.2115652 (622)\ttotal: 2m\tremaining: 8.53s\n",
      "1499:\tlearn: 0.1266891\ttest: 16.2517873\tbest: 16.2115652 (622)\ttotal: 2m 7s\tremaining: 0us\n",
      "\n",
      "bestTest = 16.21156525\n",
      "bestIteration = 622\n",
      "\n",
      "Shrink model to first 623 iterations.\n",
      "CatBoost (valid) | MAE: 7.96 | RMSE: 262.81 | R2: 0.992\n",
      "CatBoost (test) | MAE: 14.83 | RMSE: 2110.24 | R2: 0.952\n"
     ]
    }
   ],
   "source": [
    "# If this import fails: pip install catboost\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "# Identify categorical vs numeric\n",
    "cat_cols = [c for c in feature_cols if df[c].dtype == 'object']\n",
    "num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "\n",
    "def make_pool(d):\n",
    "    X = d[feature_cols].copy()\n",
    "    cat_idx = [X.columns.get_loc(c) for c in cat_cols]\n",
    "    return Pool(X, d[target], cat_features=cat_idx)\n",
    "\n",
    "train_pool = make_pool(train)\n",
    "valid_pool = make_pool(valid)\n",
    "test_pool  = make_pool(test)\n",
    "\n",
    "cat = CatBoostRegressor(\n",
    "    loss_function='RMSE',\n",
    "    depth=8,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=1500,\n",
    "    random_seed=42,\n",
    "    eval_metric='RMSE',\n",
    "    verbose=200\n",
    ")\n",
    "cat.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n",
    "\n",
    "pred_val = cat.predict(valid_pool)\n",
    "evaluate(valid[target], pred_val, \"CatBoost (valid)\")\n",
    "\n",
    "pred_test = cat.predict(test_pool)\n",
    "evaluate(test[target], pred_test, \"CatBoost (test)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9bb6974-d9ee-4d20-82ea-13d7ac458d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model -> models/production_predictor.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# Retrain on train+valid for final model\n",
    "train_valid = pd.concat([train, valid], axis=0)\n",
    "tv_pool = Pool(train_valid[feature_cols], train_valid[target],\n",
    "               cat_features=[train_valid[feature_cols].columns.get_loc(c) for c in cat_cols])\n",
    "\n",
    "cat.fit(tv_pool, verbose=False)\n",
    "joblib.dump(cat, \"models/production_predictor.joblib\")\n",
    "print(\"Saved model -> models/production_predictor.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb4479bc-4f4a-4276-abcc-933c16c2f5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== datafile.csv ====\n",
      "Columns: ['Crop', '2004-05', '2005-06', '2006-07', '2007-08', '2008-09', '2009-10', '2010-11', '2011-12']\n",
      "\n",
      "==== datafile1.csv ====\n",
      "Columns: ['Crop', 'State', 'Cost of Cultivation (`/Hectare) A2+FL', 'Cost of Cultivation (`/Hectare) C2', 'Cost of Production (`/Quintal) C2', 'Yield (Quintal/ Hectare) ']\n",
      "\n",
      "==== datafile3.csv ====\n",
      "Columns: ['Crop', 'Variety', 'Season/ duration in days', 'Recommended Zone', 'Unnamed: 4']\n",
      "\n",
      "==== produce.csv ====\n",
      "Columns: ['Particulars', 'Frequency', 'Unit', ' 3-1993', ' 3-1994', ' 3-1995', ' 3-1996', ' 3-1997', ' 3-1998', ' 3-1999', ' 3-2000', ' 3-2001', ' 3-2002', ' 3-2003', ' 3-2004', ' 3-2005', ' 3-2006', ' 3-2007', ' 3-2008', ' 3-2009', ' 3-2010', ' 3-2011', ' 3-2012', ' 3-2013', ' 3-2014']\n",
      "Particulars sample: ['Agricultural Production Foodgrains', 'Agricultural Production Foodgrains Kharif', 'Agricultural Production Foodgrains Rabi', 'Agricultural Production Foodgrains Rice', 'Agricultural Production Foodgrains Rice Kharif']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, glob, os\n",
    "\n",
    "for p in glob.glob(\"data/raw/*.csv\"):\n",
    "    if os.path.basename(p).lower() == \"datafile2.csv\":\n",
    "        continue  # we already used this\n",
    "    print(\"\\n====\", os.path.basename(p), \"====\")\n",
    "    df0 = pd.read_csv(p, nrows=5)\n",
    "    print(\"Columns:\", list(df0.columns))\n",
    "    cand = [c for c in df0.columns if str(c).lower().startswith('particular')]\n",
    "    if cand:\n",
    "        print(\"Particulars sample:\", df0[cand[0]].astype(str).head(10).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cf235b6-db1e-43af-9892-a48308bc42c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/interim/agri_combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1af0819f-2ad3-4ec0-9d32-4af0bf3e798a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: C:\\Users\\riken\\Downloads\\Agriculture_Production\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "p = Path.cwd()\n",
    "for _ in range(5):\n",
    "    if (p / \"data\").exists() and (p / \"src\").exists():\n",
    "        os.chdir(p)\n",
    "        break\n",
    "    p = p.parent\n",
    "print(\"CWD:\", Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cfcca07-c5f4-4af5-95c7-76650ebc9d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (2111, 15)\n",
      "After cleaning: (2111, 15)\n",
      "Years: [1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002] ... [2010, 2011, 2012, 2013, 2014]\n",
      "Unit counts:\n",
      " unit\n",
      "Tons    2111\n",
      "Name: count, dtype: int64\n",
      "Sources:\n",
      " source_file\n",
      "produce.csv      1740\n",
      "datafile2.csv     275\n",
      "datafile.csv       96\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"data/interim/agri_combined.csv\")\n",
    "print(\"Loaded:\", df.shape)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Numeric columns\n",
    "for col in ['production','quantity','cost','year','area_ha','yield_q_ha']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Keep valid production\n",
    "df = df[df['production'].notna() & (df['production'] >= 0)].copy()\n",
    "\n",
    "# Normalize text cols\n",
    "for col in ['crop','variety','state','season','unit','recommended_zone']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "        df.loc[df[col].isin(['nan','None','NaN']), col] = np.nan\n",
    "\n",
    "print(\"After cleaning:\", df.shape)\n",
    "print(\"Years:\", sorted(df['year'].dropna().unique().tolist())[:10], \"...\", sorted(df['year'].dropna().unique().tolist())[-5:])\n",
    "if 'unit' in df.columns:\n",
    "    print(\"Unit counts:\\n\", df['unit'].value_counts().head())\n",
    "print(\"Sources:\\n\", df['source_file'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8a8748e-5ded-4899-951e-c9b10fee52db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group keys: ['crop', 'season']\n",
      "Model rows: (302, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crop</th>\n",
       "      <th>variety</th>\n",
       "      <th>state</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>quantity</th>\n",
       "      <th>production</th>\n",
       "      <th>unit</th>\n",
       "      <th>cost</th>\n",
       "      <th>recommended_zone</th>\n",
       "      <th>...</th>\n",
       "      <th>prod_prev1</th>\n",
       "      <th>area_prev1</th>\n",
       "      <th>yield_prev1</th>\n",
       "      <th>prod_ma2</th>\n",
       "      <th>prod_prev2</th>\n",
       "      <th>area_prev2</th>\n",
       "      <th>yield_prev2</th>\n",
       "      <th>prod_delta</th>\n",
       "      <th>area_delta</th>\n",
       "      <th>yield_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Bajra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.684000</td>\n",
       "      <td>Tons</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.9313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Bajra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.423700</td>\n",
       "      <td>Tons</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.80765</td>\n",
       "      <td>7.9313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.2473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Bajra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.970100</td>\n",
       "      <td>Tons</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.05385</td>\n",
       "      <td>7.6840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Bajra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>2009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.887100</td>\n",
       "      <td>Tons</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.9701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.19690</td>\n",
       "      <td>8.4237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Bajra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.506412</td>\n",
       "      <td>Tons</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8.8871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.42860</td>\n",
       "      <td>9.9701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     crop variety state  season  year  quantity  production  unit  cost  \\\n",
       "59  Bajra     NaN   NaN  Kharif  2006       NaN    7.684000  Tons   NaN   \n",
       "60  Bajra     NaN   NaN  Kharif  2007       NaN    8.423700  Tons   NaN   \n",
       "61  Bajra     NaN   NaN  Kharif  2008       NaN    9.970100  Tons   NaN   \n",
       "62  Bajra     NaN   NaN  Kharif  2009       NaN    8.887100  Tons   NaN   \n",
       "63  Bajra     NaN   NaN  Kharif  2010       NaN    6.506412  Tons   NaN   \n",
       "\n",
       "   recommended_zone  ... prod_prev1 area_prev1  yield_prev1  prod_ma2  \\\n",
       "59              NaN  ...     7.9313        NaN          NaN       NaN   \n",
       "60              NaN  ...     7.6840        NaN          NaN   7.80765   \n",
       "61              NaN  ...     8.4237        NaN          NaN   8.05385   \n",
       "62              NaN  ...     9.9701        NaN          NaN   9.19690   \n",
       "63              NaN  ...     8.8871        NaN          NaN   9.42860   \n",
       "\n",
       "   prod_prev2  area_prev2  yield_prev2  prod_delta  area_delta  yield_delta  \n",
       "59        NaN         NaN          NaN         NaN         NaN          NaN  \n",
       "60     7.9313         NaN          NaN     -0.2473         NaN          NaN  \n",
       "61     7.6840         NaN          NaN      0.7397         NaN          NaN  \n",
       "62     8.4237         NaN          NaN      1.5464         NaN          NaN  \n",
       "63     9.9701         NaN          NaN     -1.0830         NaN          NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose grouping keys dynamically\n",
    "cand_keys = ['state','crop','season']\n",
    "keys = [k for k in cand_keys if k in df.columns and df[k].notna().any()]\n",
    "if 'crop' not in keys and 'crop' in df.columns:\n",
    "    keys = ['crop']  # at least crop\n",
    "print(\"Group keys:\", keys)\n",
    "\n",
    "# Sort and create lags\n",
    "df = df.sort_values(keys + ['year']).reset_index(drop=True)\n",
    "\n",
    "def lag(s, n): return s.shift(n)\n",
    "\n",
    "# 1-yr lags\n",
    "df['prod_prev1']  = df.groupby(keys)['production'].transform(lambda s: lag(s,1))\n",
    "if 'area_ha' in df.columns:\n",
    "    df['area_prev1']  = df.groupby(keys)['area_ha'].transform(lambda s: lag(s,1))\n",
    "if 'yield_q_ha' in df.columns:\n",
    "    df['yield_prev1'] = df.groupby(keys)['yield_q_ha'].transform(lambda s: lag(s,1))\n",
    "\n",
    "# 2-yr moving avg of production (lagged)\n",
    "df['prod_ma2'] = df.groupby(keys)['production'].transform(lambda s: lag(s,1).rolling(2).mean())\n",
    "\n",
    "# 2-yr lags for deltas\n",
    "df['prod_prev2']  = df.groupby(keys)['production'].transform(lambda s: lag(s,2))\n",
    "if 'area_ha' in df.columns:\n",
    "    df['area_prev2']  = df.groupby(keys)['area_ha'].transform(lambda s: lag(s,2))\n",
    "if 'yield_q_ha' in df.columns:\n",
    "    df['yield_prev2'] = df.groupby(keys)['yield_q_ha'].transform(lambda s: lag(s,2))\n",
    "\n",
    "# Deltas (prev1 - prev2)\n",
    "df['prod_delta']  = df['prod_prev1']  - df['prod_prev2']\n",
    "if 'area_prev1' in df.columns and 'area_prev2' in df.columns:\n",
    "    df['area_delta']  = df['area_prev1']  - df['area_prev2']\n",
    "if 'yield_prev1' in df.columns and 'yield_prev2' in df.columns:\n",
    "    df['yield_delta'] = df['yield_prev1'] - df['yield_prev2']\n",
    "\n",
    "# Keep rows with at least last year's production\n",
    "df_model = df.dropna(subset=['prod_prev1']).copy()\n",
    "print(\"Model rows:\", df_model.shape)\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13097721-1501-44dd-ad21-9c3db32a6ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Years in model: [2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014]\n",
      "Split sizes -> train: (238, 25) valid: (32, 25) test: (32, 25)\n"
     ]
    }
   ],
   "source": [
    "years = sorted(df_model['year'].dropna().unique().tolist())\n",
    "print(\"Years in model:\", years)\n",
    "\n",
    "test_year  = years[-1]\n",
    "valid_year = years[-2] if len(years) > 1 else years[-1]\n",
    "train_years = [y for y in years if y not in [valid_year, test_year]]\n",
    "\n",
    "train = df_model[df_model['year'].isin(train_years)]\n",
    "valid = df_model[df_model['year'] == valid_year]\n",
    "test  = df_model[df_model['year'] == test_year]\n",
    "print(\"Split sizes -> train:\", train.shape, \"valid:\", valid.shape, \"test:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45e2fb90-0f90-4278-9cfa-6353f9cb32dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive baseline (valid) | MAE: 14.135 | RMSE: 35.649 | R2: -0.089\n",
      "Naive baseline (test) | MAE: 13.970 | RMSE: 35.458 | R2: -0.039\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def evaluate(y_true, y_pred, name=\"\"):\n",
    "    y_true = np.asarray(y_true); y_pred = np.asarray(y_pred)\n",
    "    try:\n",
    "        rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    except TypeError:\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    print(f\"{name} | MAE: {mean_absolute_error(y_true, y_pred):.3f} | RMSE: {rmse:.3f} | R2: {r2_score(y_true, y_pred):.3f}\")\n",
    "\n",
    "evaluate(valid['production'], valid['prod_prev1'], \"Naive baseline (valid)\")\n",
    "evaluate(test['production'],  test['prod_prev1'],  \"Naive baseline (test)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28e8e1df-cbed-429d-a59e-89d77100be36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features: ['year', 'prod_prev1', 'prod_prev2', 'prod_ma2', 'prod_delta', 'crop', 'season']\n",
      "RandomForest (valid) | MAE: 1.493 | RMSE: 3.248 | R2: 0.991\n",
      "RandomForest (test) | MAE: 1.934 | RMSE: 3.610 | R2: 0.989\n"
     ]
    }
   ],
   "source": [
    "# 6) Model: RandomForest + OneHot + Imputation (handles NaNs)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Evaluation helper (compatible with older sklearn)\n",
    "def evaluate(y_true, y_pred, name=\"\"):\n",
    "    y_true = np.asarray(y_true); y_pred = np.asarray(y_pred)\n",
    "    try:\n",
    "        rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    except TypeError:\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    print(f\"{name} | MAE: {mean_absolute_error(y_true, y_pred):.3f} | RMSE: {rmse:.3f} | R2: {r2_score(y_true, y_pred):.3f}\")\n",
    "\n",
    "target = 'production'\n",
    "\n",
    "# Forecast-safe features (only lagged and past info)\n",
    "forecast_feats = [\n",
    "    'year','prod_prev1','prod_prev2','prod_ma2','prod_delta',\n",
    "    'area_prev1','area_prev2','area_delta',\n",
    "    'yield_prev1','yield_prev2','yield_delta',\n",
    "    'crop','season','state'\n",
    "]\n",
    "forecast_feats = [c for c in forecast_feats if c in df_model.columns]\n",
    "\n",
    "# Remove features that are all-NaN in any split\n",
    "def prune_feats(feats, dataframes):\n",
    "    good = []\n",
    "    for c in feats:\n",
    "        ok = True\n",
    "        for d in dataframes:\n",
    "            if c not in d.columns or d[c].dropna().shape[0] == 0:\n",
    "                ok = False; break\n",
    "        if ok: good.append(c)\n",
    "    return good\n",
    "\n",
    "feature_cols = prune_feats(forecast_feats, [train, valid, test])\n",
    "print(\"Using features:\", feature_cols)\n",
    "\n",
    "# Split columns by type\n",
    "cat_cols = [c for c in feature_cols if df_model[c].dtype == 'object']\n",
    "num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "\n",
    "# Replace inf with NaN, then impute\n",
    "for d in [train, valid, test]:\n",
    "    d.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Build transformers\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# OneHot (version-safe)\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "except TypeError:\n",
    "    try:\n",
    "        ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    except TypeError:\n",
    "        ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_imputer, num_cols),\n",
    "        ('cat', Pipeline(steps=[('imputer', cat_imputer), ('ohe', ohe)]), cat_cols),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=600,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    max_depth=None\n",
    ")\n",
    "\n",
    "pipe = Pipeline([('pre', pre), ('model', rf)])\n",
    "\n",
    "# Fit\n",
    "pipe.fit(train[feature_cols], train[target])\n",
    "\n",
    "# Validate\n",
    "pred_val = pipe.predict(valid[feature_cols])\n",
    "evaluate(valid[target], pred_val, \"RandomForest (valid)\")\n",
    "\n",
    "# Test\n",
    "pred_test = pipe.predict(test[feature_cols])\n",
    "evaluate(test[target], pred_test, \"RandomForest (test)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d0722e3-f1ea-4db5-aa21-509373b66dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved -> models/production_predictor.joblib and models/meta.json\n"
     ]
    }
   ],
   "source": [
    "import joblib, os, json\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Retrain on train+valid\n",
    "train_valid = pd.concat([train, valid], axis=0)\n",
    "pipe.fit(train_valid[feature_cols], train_valid[target])\n",
    "\n",
    "# Save model\n",
    "joblib.dump(pipe, \"models/production_predictor.joblib\")\n",
    "\n",
    "# Save meta with feature order (needed for app)\n",
    "meta = {\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"used_features\": feature_cols,  # same here\n",
    "}\n",
    "with open(\"models/meta.json\", \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Saved -> models/production_predictor.joblib and models/meta.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee9dadd7-9694-4cf4-b1ea-ffba320c2707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 09:33:39.713 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-10-21 09:33:40.079 No runtime found, using MemoryCacheStorageManager\n",
      "2025-10-21 09:33:40.088 No runtime found, using MemoryCacheStorageManager\n",
      "2025-10-21 09:33:40.140 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "# app/app.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib, json\n",
    "\n",
    "st.set_page_config(page_title=\"Crop Production Forecast\", page_icon=\"ðŸŒ¾\")\n",
    "st.title(\"Crop Production Forecast (India) ðŸŒ¾\")\n",
    "\n",
    "# Load model + meta\n",
    "model = joblib.load(\"models/production_predictor.joblib\")\n",
    "with open(\"models/meta.json\", \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "feature_cols = meta[\"feature_cols\"]\n",
    "\n",
    "# Load combined data for crop options (optional)\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    try:\n",
    "        df = pd.read_csv(\"data/interim/agri_combined.csv\")\n",
    "    except Exception:\n",
    "        df = pd.DataFrame()\n",
    "    return df\n",
    "\n",
    "df_all = load_data()\n",
    "crop_options = sorted([c for c in df_all.get('crop', pd.Series([])).dropna().unique().tolist()]) if not df_all.empty else []\n",
    "\n",
    "# Inputs\n",
    "col1, col2 = st.columns(2)\n",
    "crop = col1.selectbox(\"Crop\", options=crop_options if crop_options else [\"Wheat\",\"Rice\",\"Maize\",\"Sugarcane\"], index=0)\n",
    "season = col2.selectbox(\"Season (optional)\", options=[\"Kharif\",\"Rabi\",\"â€”\"], index=0)\n",
    "if season == \"â€”\":\n",
    "    season = None\n",
    "\n",
    "year = st.number_input(\"Forecast Year (e.g., 2012)\", min_value=1900, max_value=2100, value=2012, step=1)\n",
    "\n",
    "st.markdown(\"Provide last two years' production for this crop (Tons). If you don't know, check your dataset or leave 2-years-ago empty.\")\n",
    "prod_prev1 = st.number_input(\"Last year production (prod_prev1) [Tons]\", min_value=0.0, value=100.0, step=1.0)\n",
    "prod_prev2 = st.number_input(\"2 years ago production (prod_prev2) [Tons] (optional)\", min_value=0.0, value=0.0, step=1.0)\n",
    "\n",
    "# Derive lag features used by the model\n",
    "prod_ma2 = None\n",
    "prod_delta = None\n",
    "if prod_prev1 > 0 and prod_prev2 > 0:\n",
    "    prod_ma2 = (prod_prev1 + prod_prev2) / 2.0\n",
    "    prod_delta = prod_prev1 - prod_prev2\n",
    "else:\n",
    "    # Fallbacks if prod_prev2 unknown\n",
    "    prod_ma2 = prod_prev1\n",
    "    prod_delta = np.nan  # imputer will handle\n",
    "\n",
    "# Build input row with exactly the model's feature columns\n",
    "row = {\n",
    "    \"year\": int(year),\n",
    "    \"prod_prev1\": float(prod_prev1),\n",
    "    \"prod_prev2\": float(prod_prev2) if prod_prev2 > 0 else np.nan,\n",
    "    \"prod_ma2\": float(prod_ma2) if prod_ma2 is not None else np.nan,\n",
    "    \"prod_delta\": float(prod_delta) if prod_delta is not None else np.nan,\n",
    "    \"crop\": crop,\n",
    "    \"season\": season if season is not None else np.nan,\n",
    "}\n",
    "\n",
    "# Keep only features the model expects; add any missing as NaN\n",
    "X = pd.DataFrame([row])\n",
    "for c in feature_cols:\n",
    "    if c not in X.columns:\n",
    "        X[c] = np.nan\n",
    "X = X[feature_cols]\n",
    "\n",
    "if st.button(\"Predict\"):\n",
    "    try:\n",
    "        pred = float(model.predict(X)[0])\n",
    "        st.success(f\"Estimated production: {pred:,.2f} Tons\")\n",
    "        with st.expander(\"Model input (debug)\"):\n",
    "            st.dataframe(X)\n",
    "    except Exception as e:\n",
    "        st.error(f\"Prediction failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e6e29c-0fc8-4556-a6fc-5b6db23c9782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
